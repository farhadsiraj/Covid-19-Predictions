{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Random forest and boosting packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directories\n",
    "main_dir = \"D:\\\\Users\\\\SirajF\\\\nhc\"\n",
    "data_dir = main_dir + \"/data\"\n",
    "plot_dir = main_dir + \"/plots\"\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Check working directory.\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max column/row length\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analytic file, option to import dates as datetime commented out if necessary\n",
    "nhc_orig = pd.read_csv('nhc_covid_final 20200626.csv') #, parse_dates=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nhc_orig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep period = 2-4\n",
    "array = [2,3,4]\n",
    "nhc = nhc_orig.loc[nhc_orig['period'].isin(array)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_orig.cdc_outbreak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "nhc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc.cdc_outbreak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of data\n",
    "nhc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of columns before we drop vars\n",
    "nhc_raw = list(nhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaned dataset for random forest\n",
    "nhc_rf = nhc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all booleans to True/False\n",
    "nhc_rf = nhc_rf.applymap(lambda x: 1 if x == 'Y' else x)\n",
    "nhc_rf = nhc_rf.applymap(lambda x: 0 if x == 'N' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all booleans to 1/0\n",
    "nhc_rf = nhc_rf.applymap(lambda x: 1 if x == True else x)\n",
    "nhc_rf = nhc_rf.applymap(lambda x: 0 if x == False else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target var to bool\n",
    "nhc_rf['cdc_outbreak'] = np.where(nhc_rf['cdc_outbreak'] == 1 , True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nhc_rf['outbreak_2020-5-24'].dtypes)\n",
    "print(nhc_rf['cdc_outbreak'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf.cdc_outbreak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop misc vars\n",
    "nhc_rf = nhc_rf.drop(['provnum',\n",
    "'weekending',\n",
    "'numperiods',\n",
    "'provname',\n",
    "'facid',\n",
    "'address',\n",
    "'city',\n",
    "'state',\n",
    "'statename',\n",
    "'zip',\n",
    "'phone',\n",
    "'county',\n",
    "'FIPScty',\n",
    "'county_name',\n",
    "'cms_region',\n",
    "'cbsa_code',\n",
    "'nhc_urban',\n",
    "'nhc_sffcand',\n",
    "'nhc_comp5star',\n",
    "'nhc_qm5star',\n",
    "'nhc_staff5star',\n",
    "'nhc_rnstf5',\n",
    "'nhc_qm005',\n",
    "'nhc_qm401',\n",
    "'nhc_qm406',\n",
    "'nhc_qm407',\n",
    "'nhc_qm410',\n",
    "'nhc_qm419',\n",
    "'nhc_qm434',\n",
    "'nhc_qm451',\n",
    "'nhc_qm453',\n",
    "'nhc_qm471',\n",
    "'nhc_qm476',\n",
    "'nhc_incident_cnt',\n",
    "'pos_chow_cnt',\n",
    "'nhc_is_ccrc',\n",
    "'nhc_1st_cert_dt',\n",
    "'nhc_chng_ownr_12m',\n",
    "'nhc_srvy_gt2yrs',\n",
    "'ahrf_ctyname',\n",
    "'ahrf_hcd_pctmcradvtg2018',\n",
    "'ahrf_ecn_pctpvrty2017',\n",
    "'ahrf_ecn_unemprt2018',\n",
    "'ahrf_oth_airqlty2018',\n",
    "'reg_dum1',\n",
    "'reg_dum2',\n",
    "'reg_dum3',\n",
    "'reg_dum4',\n",
    "'div_dum1',\n",
    "'div_dum2',\n",
    "'div_dum3',\n",
    "'div_dum4',\n",
    "'div_dum5',\n",
    "'div_dum6',\n",
    "'div_dum7',\n",
    "'div_dum8',\n",
    "'div_dum9',\n",
    "'ahrf_dmg_lo19_2017',\n",
    "'ahrf_dmg_2034_2017',\n",
    "'ahrf_dmg_3564_2017',\n",
    "'cdc_submitteddata',\n",
    "'cdc_passedqualcheck',\n",
    "'cdc_c19admissions_res_week',\n",
    "'cdc_c19admissions_res',\n",
    "'cdc_c19confirmed_res_week',\n",
    "'cdc_c19confirmed_res',\n",
    "'cdc_c19confirmed_res_perc',\n",
    "'cdc_c19suspected_res_week',\n",
    "'cdc_c19suspected_res',\n",
    "'cdc_c19deaths_res_week',\n",
    "'cdc_c19deaths_res',\n",
    "'cdc_c19deaths_res_perc',\n",
    "'cdc_c19deaths_res_percconfirmed',\n",
    "'cdc_c19confirmed_staff_week',\n",
    "'cdc_c19confirmed_staff',\n",
    "'cdc_c19suspected_staff_week',\n",
    "'cdc_c19suspected_staff',\n",
    "'cdc_c19deaths_staff_week',\n",
    "'cdc_c19deaths_staff',\n",
    "'cdc_alldeaths_res_week',\n",
    "'cdc_alldeaths_res',\n",
    "'cdc_beds',\n",
    "'cdc_occupiedbeds',\n",
    "'cdc_testing_res',\n",
    "'cdc_shortage_nursingstaff',\n",
    "'cdc_shortage_clinicalstaff',\n",
    "'cdc_shortage_aides',\n",
    "'cdc_shortage_otherstaff',\n",
    "'cdc_weeksupply_n95mask',\n",
    "'cdc_weeksupply_surgmask',\n",
    "'cdc_weeksupply_eyeprotection',\n",
    "'cdc_weeksupply_gowns',\n",
    "'cdc_weeksupply_gloves',\n",
    "'cdc_weeksupply_sanitizer',\n",
    "'cdc_ventilatordepunit',\n",
    "'cdc_numventilator',\n",
    "'cdc_numventilator_c19use',\n",
    "'cdc_weeksupply_ventilator',\n",
    "'cdc_geolocationstate',\n",
    "'cdc_geolocation'\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NAN with 0\n",
    "nhc_rf = nhc_rf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf.cdc_outbreak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of column names with total cases by week\n",
    "totcase_week = list(nhc.columns[nhc.columns.str.startswith('usa_totcase_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totcase_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep period = 2 or 3\n",
    "array1 = [2,3]\n",
    "nhc_rf_test = nhc_rf.loc[nhc_rf['period'].isin(array1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target week we are trying to predict\n",
    "targetweek = 'usa_totcase_wk0531'\n",
    "targetweek_cntg = 'usa_totcase_wk0531_cntg'\n",
    "\n",
    "\n",
    "targetweek2 = 'usa_totcase_wk0607'\n",
    "targetweek_cntg2 = 'usa_totcase_wk0607_cntg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to find vars for 3 to 7 weeks before target\n",
    "def find_adjacents(value, items, x):\n",
    "    i = items.index(value)\n",
    "    return items[i-x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store function output as var for each week\n",
    "wago3_0531 = (find_adjacents(targetweek, totcase_week, 3))\n",
    "wago4_0531 = (find_adjacents(targetweek, totcase_week, 4))\n",
    "wago5_0531 = (find_adjacents(targetweek, totcase_week, 5))\n",
    "wago6_0531 = (find_adjacents(targetweek, totcase_week, 6))\n",
    "wago7_0531 = (find_adjacents(targetweek, totcase_week, 7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wago3_cntg_0531 = (find_adjacents(targetweek_cntg, totcase_week, 3))\n",
    "wago4_cntg_0531 = (find_adjacents(targetweek_cntg, totcase_week, 4))\n",
    "wago5_cntg_0531 = (find_adjacents(targetweek_cntg, totcase_week, 5))\n",
    "wago6_cntg_0531 = (find_adjacents(targetweek_cntg, totcase_week, 6))\n",
    "wago7_cntg_0531 = (find_adjacents(targetweek_cntg, totcase_week, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store function output as var for each week\n",
    "wago3_0607 = (find_adjacents(targetweek2, totcase_week, 3))\n",
    "wago4_0607 = (find_adjacents(targetweek2, totcase_week, 4))\n",
    "wago5_0607 = (find_adjacents(targetweek2, totcase_week, 5))\n",
    "wago6_0607 = (find_adjacents(targetweek2, totcase_week, 6))\n",
    "wago7_0607 = (find_adjacents(targetweek2, totcase_week, 7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wago3_cntg_0607 = (find_adjacents(targetweek_cntg2, totcase_week, 3))\n",
    "wago4_cntg_0607 = (find_adjacents(targetweek_cntg2, totcase_week, 4))\n",
    "wago5_cntg_0607 = (find_adjacents(targetweek_cntg2, totcase_week, 5))\n",
    "wago6_cntg_0607 = (find_adjacents(targetweek_cntg2, totcase_week, 6))\n",
    "wago7_cntg_0607 = (find_adjacents(targetweek_cntg2, totcase_week, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to check the weeks are correct\n",
    "print(\"5/31/2020\")\n",
    "print(wago3_0531) \n",
    "print(wago4_0531) \n",
    "print(wago5_0531) \n",
    "print(wago6_0531) \n",
    "print(wago7_0531) \n",
    "\n",
    "print(wago3_cntg_0531)\n",
    "print(wago4_cntg_0531) \n",
    "print(wago5_cntg_0531) \n",
    "print(wago6_cntg_0531) \n",
    "print(wago7_cntg_0531) \n",
    "\n",
    "print(\"6/7/2020\")\n",
    "print(wago3_0607) \n",
    "print(wago4_0607) \n",
    "print(wago5_0607) \n",
    "print(wago6_0607) \n",
    "print(wago7_0607) \n",
    "\n",
    "print(wago3_cntg_0607)\n",
    "print(wago4_cntg_0607) \n",
    "print(wago5_cntg_0607) \n",
    "print(wago6_cntg_0607) \n",
    "print(wago7_cntg_0607) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the week vars to the data set\n",
    "nhc_rf_test['case_3wago'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago3_0531], nhc_rf_test[wago3_0607])\n",
    "nhc_rf_test['case_4wago'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago4_0531], nhc_rf_test[wago4_0607])\n",
    "nhc_rf_test['case_5wago'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago5_0531], nhc_rf_test[wago5_0607])\n",
    "nhc_rf_test['case_6wago'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago6_0531], nhc_rf_test[wago6_0607])\n",
    "nhc_rf_test['case_7wago'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago7_0531], nhc_rf_test[wago7_0607])\n",
    "\n",
    "nhc_rf_test['case_3wago_cntg'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago3_cntg_0531], nhc_rf_test[wago3_cntg_0607])\n",
    "nhc_rf_test['case_4wago_cntg'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago4_cntg_0531], nhc_rf_test[wago4_cntg_0607])\n",
    "nhc_rf_test['case_5wago_cntg'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago5_cntg_0531], nhc_rf_test[wago5_cntg_0607])\n",
    "nhc_rf_test['case_6wago_cntg'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago6_cntg_0531], nhc_rf_test[wago6_cntg_0607])\n",
    "nhc_rf_test['case_7wago_cntg'] = np.where(nhc_rf_test['period']==2,  nhc_rf_test[wago7_cntg_0531], nhc_rf_test[wago7_cntg_0607])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_test = nhc_rf_test.drop(['usa_totcase_wk0308',\n",
    " 'usa_totcase_wk0315',\n",
    " 'usa_totcase_wk0322',\n",
    " 'usa_totcase_wk0329',\n",
    " 'usa_totcase_wk0405',\n",
    " 'usa_totcase_wk0412',\n",
    " 'usa_totcase_wk0419',\n",
    " 'usa_totcase_wk0426',\n",
    " 'usa_totcase_wk0503',\n",
    " 'usa_totcase_wk0510',\n",
    " 'usa_totcase_wk0517',\n",
    " 'usa_totcase_wk0524',\n",
    " 'usa_totcase_wk0531',\n",
    " 'usa_totcase_wk0607',\n",
    " 'usa_totcase_wk0614',\n",
    " 'usa_totcase_wk0621',\n",
    " 'usa_totcase_wk0308_cntg',\n",
    " 'usa_totcase_wk0315_cntg',\n",
    " 'usa_totcase_wk0322_cntg',\n",
    " 'usa_totcase_wk0329_cntg',\n",
    " 'usa_totcase_wk0405_cntg',\n",
    " 'usa_totcase_wk0412_cntg',\n",
    " 'usa_totcase_wk0419_cntg',\n",
    " 'usa_totcase_wk0426_cntg',\n",
    " 'usa_totcase_wk0503_cntg',\n",
    " 'usa_totcase_wk0510_cntg',\n",
    " 'usa_totcase_wk0517_cntg',\n",
    " 'usa_totcase_wk0524_cntg',\n",
    " 'usa_totcase_wk0531_cntg',\n",
    " 'usa_totcase_wk0607_cntg',\n",
    " 'usa_totcase_wk0614_cntg',\n",
    " 'usa_totcase_wk0621_cntg',\n",
    " 'period'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create list of columns after cleans for comparison\n",
    "nhc_clean = list(nhc_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_vars = list(set(nhc_raw) - set(nhc_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_test.cdc_outbreak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the cleaned dataset\n",
    "pickle.dump(nhc_rf_test, open(\"nhc_covid19_rf_test.csv\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the predictors and target.\n",
    "X = nhc_rf_test.drop(['cdc_outbreak'], axis = 1)\n",
    "\n",
    "y = np.array(nhc_rf_test['cdc_outbreak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to 1.\n",
    "seed = 1\n",
    "\n",
    "# Split into the training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=seed)\n",
    "\n",
    "# Balancing data with SMOTE\n",
    "sm = SMOTE(random_state=seed)\n",
    "X_train, y_train = sm.fit_sample(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_rf = list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "forest = RandomForestClassifier(criterion = 'gini',\n",
    "                                n_estimators = 500,\n",
    "                                random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the saved model to your training data.\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data.\n",
    "y_predict_forest = forest.predict(X_test)\n",
    "\n",
    "# Look at the first few predictions.\n",
    "print(y_predict_forest[0:50,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_forest = metrics.confusion_matrix(y_test, y_predict_forest)\n",
    "print(conf_matrix_forest)\n",
    "accuracy_forest = metrics.accuracy_score(y_test, y_predict_forest)\n",
    "print(\"Accuracy for random forest on test data: \", accuracy_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.imshow(conf_matrix_forest, interpolation='nearest', cmap=plt.cm.tab20)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Nursing Home Compare Outbreak Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j-0.25,i, str(s[i][j])+\" = \"+str(conf_matrix_forest[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using training data.\n",
    "acc_train_forest = forest.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", acc_train_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with accuracy values for model \n",
    "model_final_dict = {'metrics': [\"accuracy\"],\n",
    "               'values':[round(accuracy_forest,4)],\n",
    "                'model':['random_forest_05312020']}\n",
    "model_final = pd.DataFrame(data = model_final_dict)\n",
    "print(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_features = nhc_rf_test.drop('cdc_outbreak', axis = 1)\n",
    "features = nhc_rf_features.columns\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,30)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), labels)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test.\n",
    "forest_y_predict = forest.predict(X_test)\n",
    "print(forest_y_predict[:5])\n",
    "#Predict on test, but instead of labels\n",
    "# we will get probabilities for class 0 and 1.\n",
    "forest_y_predict_prob = forest.predict_proba(X_test)\n",
    "print(forest_y_predict_prob[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_scores(y_test, y_predict, y_predict_prob, eps=1e-15, beta=0.5):\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Scores keys.\n",
    "    metric_keys = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"fbeta\", \"log_loss\", \"AUC\"]\n",
    "\n",
    "    # Score values.\n",
    "    metric_values = [None]*len(metric_keys)\n",
    "\n",
    "    metric_values[0] = metrics.accuracy_score(y_test, y_predict)\n",
    "    metric_values[1] = metrics.precision_score(y_test, y_predict)\n",
    "    metric_values[2] = metrics.recall_score(y_test, y_predict)\n",
    "    metric_values[3] = metrics.f1_score(y_test, y_predict)\n",
    "    metric_values[4] = metrics.fbeta_score(y_test, y_predict, beta=beta)\n",
    "    metric_values[5] = metrics.log_loss(y_test, y_predict_prob[:, 1], eps=eps)\n",
    "    metric_values[6] = metrics.roc_auc_score(y_test, y_predict_prob[:, 1])\n",
    "\n",
    "    perf_metrics = dict(zip(metric_keys, metric_values))\n",
    "\n",
    "    return(perf_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = get_performance_scores(y_test, forest_y_predict, forest_y_predict_prob)\n",
    "\n",
    "ensemble_methods_metrics = {\"RF\": forest_scores}\n",
    "print(ensemble_methods_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_roc = metrics.plot_roc_curve(forest, X_test, y_test, name = \"RF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(forest, open(\"nhc_covid19_rfmodel.sav\",\"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]\n",
    "\n",
    "# Number of features to consider at every split.\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree.\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node.\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node.\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Set Minimal Cost-Complexity Pruning parameter (has to be >= 0.0).\n",
    "ccp_alpha = [0.0, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# Create the random grid\n",
    "# (a python dictionary in a form `'parameter_name': parameter_values`)\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'ccp_alpha': ccp_alpha}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = forest, #<- model object\n",
    "                               param_distributions = random_grid, #<- param grid\n",
    "                               n_iter = 100,#<- number of param. settings sampled\n",
    "                               cv = 3,      #<- 3-fold CV\n",
    "                               verbose = 0, #<- silence lengthy output to console\n",
    "                               random_state = 1, #<- set random state\n",
    "                               n_jobs = -1)      #<- use all available processors\n",
    "\n",
    "# Fit the random search model.\n",
    "rf_random.fit(X_train, y_train) #<- fit like any other scikit-learn model\n",
    "# Take a look at optimal combination of parameters.\n",
    "print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_random, open(\"rf_random_0627.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = pickle.load(open(\"rf_random_0627.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass best parameters obtained through randomized search to RF classifier.\n",
    "optimized_forest = RandomForestClassifier(**rf_random.best_params_)\n",
    "\n",
    "# Train the optimized RF model.\n",
    "optimized_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data.\n",
    "optimized_forest_y_predict = optimized_forest.predict(X_test)\n",
    "\n",
    "# Get predicted probabilities.\n",
    "optimized_forest_y_predict_proba = optimized_forest.predict_proba(X_test)\n",
    "# Compute performance scores.\n",
    "optimized_forest_scores = get_performance_scores(y_test,\n",
    "optimized_forest_y_predict,\n",
    "optimized_forest_y_predict_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_forest_opt = metrics.confusion_matrix(y_test, optimized_forest_y_predict)\n",
    "print(conf_matrix_forest_opt)\n",
    "accuracy_forest_opt = metrics.accuracy_score(y_test, optimized_forest_y_predict)\n",
    "print(\"Accuracy for random forest on test data: \", accuracy_forest_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.imshow(conf_matrix_forest_opt, interpolation='nearest', cmap=plt.cm.tab20)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Nursing Home Compare Outbreak Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j-0.25,i, str(s[i][j])+\" = \"+str(conf_matrix_forest_opt[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_rf_features_opt = nhc_rf_test.drop('cdc_outbreak', axis = 1)\n",
    "features = nhc_rf_features.columns\n",
    "importances = optimized_forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[0:15][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,30)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), labels)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, importance in zip(nhc_rf_features_opt.columns, optimized_forest.feature_importances_):\n",
    "    print ('feature: {f}, importance: {i}'.format(f=feat, i=importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_rf_roc = metrics.plot_roc_curve(optimized_forest,\n",
    "                                    X_test,\n",
    "                                    y_test,\n",
    "                                    name = \"Optimized RF\",\n",
    "                                    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_forest_scores = get_performance_scores(y_test, optimized_forest_y_predict, optimized_forest_y_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_methods_metrics.update({\"Optimized RF\": optimized_forest_scores})\n",
    "print(ensemble_methods_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metrics dictionary to dataframe\n",
    "\n",
    "# Convert all metrics for each model to a dataframe.\n",
    "ensemble_methods_metrics_df = pd.DataFrame(ensemble_methods_metrics)\n",
    "ensemble_methods_metrics_df[\"metric\"] = ensemble_methods_metrics_df.index\n",
    "ensemble_methods_metrics_df = ensemble_methods_metrics_df.reset_index(drop = True)\n",
    "print(ensemble_methods_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(optimized_forest, open(\"nhc_covid19_rfmodel_optimized.sav\",\"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters we will be using for our gradient boosting classifier.\n",
    "gbm = GradientBoostingClassifier(n_estimators = 200, \n",
    "                                learning_rate = 1,\n",
    "                                max_depth = 2, \n",
    "                                random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the saved model to the training data.\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data.\n",
    "predicted_values_gbm = gbm.predict(X_test)\n",
    "print(predicted_values_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_boosting = metrics.confusion_matrix(y_test, predicted_values_gbm)\n",
    "print(conf_matrix_boosting)\n",
    "# Compute test model accuracy score.\n",
    "accuracy_gbm = metrics.accuracy_score(y_test, predicted_values_gbm)\n",
    "print('Accuracy of gbm on test data: ', accuracy_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.imshow(conf_matrix_boosting, interpolation='nearest', cmap=plt.cm.tab20)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Nursing Home Compare Outbreak GBM Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j-0.25,i, str(s[i][j])+\" = \"+str(conf_matrix_boosting[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using training data.\n",
    "train_accuracy_gbm = gbm.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", train_accuracy_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with accuracy values for model \n",
    "model_final_dict = {'metrics': [\"accuracy\"],\n",
    "               'values':[round(accuracy_gbm,4)],\n",
    "                'model':['train_gbm_20200628']}\n",
    "model_final = pd.DataFrame(data = model_final_dict)\n",
    "print(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nhc_gbm_features = nhc_rf_test.drop('cdc_outbreak', axis = 1)\n",
    "features = nhc_gbm_features.columns\n",
    "importances = gbm.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,30)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), labels)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gbm, open(\"nhc_covid19_gbm_20200628.sav\",\"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test.\n",
    "gbm_y_predict = gbm.predict(X_test)\n",
    "print(gbm_y_predict[:5])\n",
    "#Predict on test, but instead of labels\n",
    "# we will get probabilities for class 0 and 1.\n",
    "gbm_y_predict_prob = gbm.predict_proba(X_test)\n",
    "print(gbm_y_predict_prob[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_scores(y_test, y_predict, y_predict_prob, eps=1e-15, beta=0.5):\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Scores keys.\n",
    "    metric_keys = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"fbeta\", \"log_loss\", \"AUC\"]\n",
    "\n",
    "    # Score values.\n",
    "    metric_values = [None]*len(metric_keys)\n",
    "\n",
    "    metric_values[0] = metrics.accuracy_score(y_test, y_predict)\n",
    "    metric_values[1] = metrics.precision_score(y_test, y_predict)\n",
    "    metric_values[2] = metrics.recall_score(y_test, y_predict)\n",
    "    metric_values[3] = metrics.f1_score(y_test, y_predict)\n",
    "    metric_values[4] = metrics.fbeta_score(y_test, y_predict, beta=beta)\n",
    "    metric_values[5] = metrics.log_loss(y_test, y_predict_prob[:, 1], eps=eps)\n",
    "    metric_values[6] = metrics.roc_auc_score(y_test, y_predict_prob[:, 1])\n",
    "\n",
    "    perf_metrics = dict(zip(metric_keys, metric_values))\n",
    "\n",
    "    return(perf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_scores = get_performance_scores(y_test, gbm_y_predict, gbm_y_predict_prob)\n",
    "ensemble_methods_metrics.update({\"GBM\": gbm_scores})\n",
    "print(ensemble_methods_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_roc = metrics.plot_roc_curve(gbm, X_test, y_test, name = \"GBM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gbm, open(\"nhc_covid19_gbmmodel.sav\",\"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized CV for GBM optimization: parameters \n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "# Number of trees in random forest.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]\n",
    "\n",
    "# Number of features to consider at every split.\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree.\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node.\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node.\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Define learning rate parameters.\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# Create the random grid.\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'learning_rate': learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized CV for GBM optimization: fit \n",
    "\n",
    "# Initialize the randomized search model\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100,\n",
    "                               cv = 3,\n",
    "                               verbose = 0,\n",
    "                               random_state = 1,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "Fit the random search model.\n",
    "gbm_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-saved randomized search CV model.\n",
    "gbm_random = pickle.load(open(\"gbm_random.sav\",\"rb\"))\n",
    "gbm_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_random = pickle.load(open(\"nhc_covid19_gbm_test.csv\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement optimized GBM model\n",
    "\n",
    "# Pass parameters from randomized search to GBM classifier.\n",
    "optimized_gbm = GradientBoostingClassifier(**gbm_random.best_params_)\n",
    "\n",
    "# Fit model to train data.\n",
    "optimized_gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate optimized GBM model\n",
    "\n",
    "# Get class predictions.\n",
    "optimized_gbm_y_predict = gbm_random.predict(X_test)\n",
    "\n",
    "# Get prediction probabilities.\n",
    "optimized_gbm_y_predict_proba = optimized_gbm.predict_proba(X_test)\n",
    "\n",
    "# Compute performance metrics.\n",
    "optimized_gbm_scores = get_performance_scores(y_test,\n",
    "optimized_gbm_y_predict,\n",
    "optimized_gbm_y_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_gbm_scores = get_performance_scores(y_test, optimized_gbm_y_predict, optimized_gbm_y_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_boosting_opt = metrics.confusion_matrix(y_test, optimized_gbm_y_predict)\n",
    "print(conf_matrix_boosting_opt)\n",
    "# Compute test model accuracy score.\n",
    "accuracy_gbm_opt = metrics.accuracy_score(y_test, optimized_gbm_y_predict)\n",
    "print('Accuracy of gbm on test data: ', accuracy_gbm_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.imshow(conf_matrix_boosting_opt, interpolation='nearest', cmap=plt.cm.tab20)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Nursing Home Compare Outbreak GBM Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j-0.25,i, str(s[i][j])+\" = \"+str(conf_matrix_boosting_opt[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy using training data.\n",
    "train_accuracy_gbm_opt = optimized_gbm.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", train_accuracy_gbm_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with accuracy values for model \n",
    "model_final_dict = {'metrics': [\"accuracy\"],\n",
    "               'values':[round(accuracy_gbm,4)],\n",
    "                'model':['train_gbm_20200628']}\n",
    "model_final = pd.DataFrame(data = model_final_dict)\n",
    "print(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nhc_gbm_features_opt = nhc_rf_test.drop('cdc_outbreak', axis = 1)\n",
    "features = nhc_gbm_features_opt.columns\n",
    "importances = optimized_gbm.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,30)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), labels)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_methods_metrics.update({\"Optimized GBM\": optimized_gbm_scores})\n",
    "print(ensemble_methods_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "lw = 2\n",
    "ax = plt.gca()\n",
    "opt_gbm_roc = metrics.plot_roc_curve(optimized_gbm,\n",
    "                                     X_test,\n",
    "                                     y_test,\n",
    "                                     ax = ax,\n",
    "                                     name = \"Optimized GBM\")\n",
    "\n",
    "rf_roc.plot(ax = ax, name = \"RF\")\n",
    "opt_rf_roc.plot(ax = ax, name = \"Optimized RF\")\n",
    "gbm_roc.plot(ax = ax, name = \"GBM\")\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "ax = plt.gca()\n",
    "opt_gbm_roc = metrics.plot_roc_curve(optimized_gbm,\n",
    "                                     X_test,\n",
    "                                     y_test,\n",
    "                                     ax = ax,\n",
    "                                     name = \"Optimized GBM\")\n",
    "\n",
    "\n",
    "opt_rf_roc.plot(ax = ax, name = \"Optimized RF\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all metrics for each model to a dataframe.\n",
    "ensemble_methods_metrics_df = pd.DataFrame(ensemble_methods_metrics)\n",
    "ensemble_methods_metrics_df[\"metric\"] = ensemble_methods_metrics_df.index\n",
    "ensemble_methods_metrics_df = ensemble_methods_metrics_df.reset_index(drop = True)\n",
    "print(ensemble_methods_metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict 6/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep period = 2 or 3\n",
    "array2 = [4]\n",
    "nhc_pred0614 = nhc_rf.loc[nhc_rf['period'].isin(array2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0614.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totcase_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target week we are trying to predict\n",
    "targetweek = 'usa_totcase_wk0614'\n",
    "targetweek_cntg = 'usa_totcase_wk0614_cntg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to find vars for 3 to 7 weeks before target\n",
    "def find_adjacents(value, items, x):\n",
    "    i = items.index(value)\n",
    "    return items[i-x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store function output as var for each week\n",
    "wago3_0614 = (find_adjacents(targetweek, totcase_week, 3))\n",
    "wago4_0614 = (find_adjacents(targetweek, totcase_week, 4))\n",
    "wago5_0614 = (find_adjacents(targetweek, totcase_week, 5))\n",
    "wago6_0614 = (find_adjacents(targetweek, totcase_week, 6))\n",
    "wago7_0614 = (find_adjacents(targetweek, totcase_week, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wago3_cntg_0614 = (find_adjacents(targetweek_cntg, totcase_week, 3))\n",
    "wago4_cntg_0614 = (find_adjacents(targetweek_cntg, totcase_week, 4))\n",
    "wago5_cntg_0614 = (find_adjacents(targetweek_cntg, totcase_week, 5))\n",
    "wago6_cntg_0614 = (find_adjacents(targetweek_cntg, totcase_week, 6))\n",
    "wago7_cntg_0614 = (find_adjacents(targetweek_cntg, totcase_week, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to check the weeks are correct\n",
    "print(\"6/14/2020\")\n",
    "print(wago3_0614) \n",
    "print(wago4_0614) \n",
    "print(wago5_0614) \n",
    "print(wago6_0614) \n",
    "print(wago7_0614) \n",
    "\n",
    "print(wago3_cntg_0614)\n",
    "print(wago4_cntg_0614) \n",
    "print(wago5_cntg_0614) \n",
    "print(wago6_cntg_0614) \n",
    "print(wago7_cntg_0614) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the week vars to the data set\n",
    "nhc_pred0614['case_3wago'] =   nhc_pred0614[wago3_0614] \n",
    "nhc_pred0614['case_4wago'] =   nhc_pred0614[wago4_0614]\n",
    "nhc_pred0614['case_5wago'] =   nhc_pred0614[wago5_0614] \n",
    "nhc_pred0614['case_6wago'] =   nhc_pred0614[wago6_0614] \n",
    "nhc_pred0614['case_7wago'] =   nhc_pred0614[wago7_0614]\n",
    "\n",
    "nhc_pred0614['case_3wago_cntg'] =   nhc_pred0614[wago3_cntg_0614] \n",
    "nhc_pred0614['case_4wago_cntg'] =   nhc_pred0614[wago4_cntg_0614] \n",
    "nhc_pred0614['case_5wago_cntg'] =   nhc_pred0614[wago5_cntg_0614] \n",
    "nhc_pred0614['case_6wago_cntg'] =   nhc_pred0614[wago6_cntg_0614]\n",
    "nhc_pred0614['case_7wago_cntg'] =   nhc_pred0614[wago7_cntg_0614]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0614.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0614 = nhc_pred0614.drop(['usa_totcase_wk0308',\n",
    " 'usa_totcase_wk0315',\n",
    " 'usa_totcase_wk0322',\n",
    " 'usa_totcase_wk0329',\n",
    " 'usa_totcase_wk0405',\n",
    " 'usa_totcase_wk0412',\n",
    " 'usa_totcase_wk0419',\n",
    " 'usa_totcase_wk0426',\n",
    " 'usa_totcase_wk0503',\n",
    " 'usa_totcase_wk0510',\n",
    " 'usa_totcase_wk0517',\n",
    " 'usa_totcase_wk0524',\n",
    " 'usa_totcase_wk0531',\n",
    " 'usa_totcase_wk0607',\n",
    " 'usa_totcase_wk0614',\n",
    " 'usa_totcase_wk0621',\n",
    " 'usa_totcase_wk0308_cntg',\n",
    " 'usa_totcase_wk0315_cntg',\n",
    " 'usa_totcase_wk0322_cntg',\n",
    " 'usa_totcase_wk0329_cntg',\n",
    " 'usa_totcase_wk0405_cntg',\n",
    " 'usa_totcase_wk0412_cntg',\n",
    " 'usa_totcase_wk0419_cntg',\n",
    " 'usa_totcase_wk0426_cntg',\n",
    " 'usa_totcase_wk0503_cntg',\n",
    " 'usa_totcase_wk0510_cntg',\n",
    " 'usa_totcase_wk0517_cntg',\n",
    " 'usa_totcase_wk0524_cntg',\n",
    " 'usa_totcase_wk0531_cntg',\n",
    " 'usa_totcase_wk0607_cntg',\n",
    " 'usa_totcase_wk0614_cntg',\n",
    " 'usa_totcase_wk0621_cntg',\n",
    " 'period',\n",
    " 'cdc_outbreak'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict an outbreak with best model here\n",
    "nhc_pred0614_pred = optimized_forest.predict(nhc_pred0614)\n",
    "print(nhc_pred0614_pred[0:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_forest.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict an outbreak with best model here\n",
    "nhc_pred0614_prob = optimized_forest.predict_proba(nhc_pred0614)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0614_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append predictions to dataset\n",
    "nhc_pred0614['pred_outbreak_0614'] = nhc_pred0614_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0614['pred_outbreak_prob_0614'] = nhc_pred0614_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0614"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict 7/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep period = 4\n",
    "array2 = [4]\n",
    "nhc_pred0712 = nhc_rf.loc[nhc_rf['period'].isin(array2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0712.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totcase_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target week we are trying to predict\n",
    "targetweek = 'usa_totcase_wk0621'\n",
    "targetweek_cntg = 'usa_totcase_wk0621_cntg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store function output as var for each week\n",
    "wago3_0712 = (find_adjacents(targetweek, totcase_week, 0))\n",
    "wago4_0712 = (find_adjacents(targetweek, totcase_week, 1))\n",
    "wago5_0712 = (find_adjacents(targetweek, totcase_week, 2))\n",
    "wago6_0712 = (find_adjacents(targetweek, totcase_week, 3))\n",
    "wago7_0712 = (find_adjacents(targetweek, totcase_week, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wago3_cntg_0712 = (find_adjacents(targetweek_cntg, totcase_week, 0))\n",
    "wago4_cntg_0712 = (find_adjacents(targetweek_cntg, totcase_week, 1))\n",
    "wago5_cntg_0712 = (find_adjacents(targetweek_cntg, totcase_week, 2))\n",
    "wago6_cntg_0712 = (find_adjacents(targetweek_cntg, totcase_week, 3))\n",
    "wago7_cntg_0712 = (find_adjacents(targetweek_cntg, totcase_week, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to check the weeks are correct\n",
    "print(\"7/12/2020\")\n",
    "print(wago3_0712) \n",
    "print(wago4_0712) \n",
    "print(wago5_0712) \n",
    "print(wago6_0712) \n",
    "print(wago7_0712) \n",
    "\n",
    "print(wago3_cntg_0712)\n",
    "print(wago4_cntg_0712) \n",
    "print(wago5_cntg_0712) \n",
    "print(wago6_cntg_0712) \n",
    "print(wago7_cntg_0712) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the week vars to the data set\n",
    "nhc_pred0712['case_3wago'] =   nhc_pred0712[wago3_0712] \n",
    "nhc_pred0712['case_4wago'] =   nhc_pred0712[wago4_0712]\n",
    "nhc_pred0712['case_5wago'] =   nhc_pred0712[wago5_0712] \n",
    "nhc_pred0712['case_6wago'] =   nhc_pred0712[wago6_0712] \n",
    "nhc_pred0712['case_7wago'] =   nhc_pred0712[wago7_0712]\n",
    "\n",
    "nhc_pred0712['case_3wago_cntg'] =   nhc_pred0712[wago3_cntg_0712] \n",
    "nhc_pred0712['case_4wago_cntg'] =   nhc_pred0712[wago4_cntg_0712] \n",
    "nhc_pred0712['case_5wago_cntg'] =   nhc_pred0712[wago5_cntg_0712] \n",
    "nhc_pred0712['case_6wago_cntg'] =   nhc_pred0712[wago6_cntg_0712]\n",
    "nhc_pred0712['case_7wago_cntg'] =   nhc_pred0712[wago7_cntg_0712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0712.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0712 = nhc_pred0712.drop(['usa_totcase_wk0308',\n",
    " 'usa_totcase_wk0315',\n",
    " 'usa_totcase_wk0322',\n",
    " 'usa_totcase_wk0329',\n",
    " 'usa_totcase_wk0405',\n",
    " 'usa_totcase_wk0412',\n",
    " 'usa_totcase_wk0419',\n",
    " 'usa_totcase_wk0426',\n",
    " 'usa_totcase_wk0503',\n",
    " 'usa_totcase_wk0510',\n",
    " 'usa_totcase_wk0517',\n",
    " 'usa_totcase_wk0524',\n",
    " 'usa_totcase_wk0531',\n",
    " 'usa_totcase_wk0607',\n",
    " 'usa_totcase_wk0614',\n",
    " 'usa_totcase_wk0621',\n",
    " 'usa_totcase_wk0308_cntg',\n",
    " 'usa_totcase_wk0315_cntg',\n",
    " 'usa_totcase_wk0322_cntg',\n",
    " 'usa_totcase_wk0329_cntg',\n",
    " 'usa_totcase_wk0405_cntg',\n",
    " 'usa_totcase_wk0412_cntg',\n",
    " 'usa_totcase_wk0419_cntg',\n",
    " 'usa_totcase_wk0426_cntg',\n",
    " 'usa_totcase_wk0503_cntg',\n",
    " 'usa_totcase_wk0510_cntg',\n",
    " 'usa_totcase_wk0517_cntg',\n",
    " 'usa_totcase_wk0524_cntg',\n",
    " 'usa_totcase_wk0531_cntg',\n",
    " 'usa_totcase_wk0607_cntg',\n",
    " 'usa_totcase_wk0614_cntg',\n",
    " 'usa_totcase_wk0621_cntg',                                \n",
    " 'period',\n",
    " 'cdc_outbreak'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict an outbreak with best model here\n",
    "nhc_pred0712_pred = optimized_forest.predict(nhc_pred0712)\n",
    "print(nhc_pred0712_pred[0:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_forest.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict an outbreak with best model here\n",
    "nhc_pred0712_prob = optimized_forest.predict_proba(nhc_pred0712)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0712_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append predictions to dataset\n",
    "nhc_pred0712['pred_outbreak_0712'] = nhc_pred0712_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0712['pred_outbreak_prob_0712'] = nhc_pred0712_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_pred0712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep period = 2-4\n",
    "array = [4]\n",
    "nhc_final = nhc_orig.loc[nhc_orig['period'].isin(array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append predictions to dataset\n",
    "nhc_final['pred_outbreak_0614'] = nhc_pred0614_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nhc_final['pred_outbreak_prob_0614'] = nhc_pred0614_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append predictions to dataset\n",
    "nhc_final['pred_outbreak_0712'] = nhc_pred0712_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final['pred_outbreak_prob_0712'] = nhc_pred0712_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final.pred_outbreak_0614.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final.pred_outbreak_0712.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target var to bool\n",
    "nhc_final['cdc_outbreak'] = np.where(nhc_final['cdc_outbreak'] == 1 , True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final['correct_pred'] = np.where(nhc_final['cdc_outbreak']==nhc_final['pred_outbreak_0614'], \"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final.correct_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_at_end = ['cdc_outbreak', 'pred_outbreak_0614', 'pred_outbreak_prob_0614', 'correct_pred', 'pred_outbreak_0712', 'pred_outbreak_prob_0712']\n",
    "nhc_final = nhc_final[[c for c in nhc_final if c not in cols_at_end]+ [c for c in cols_at_end if c in nhc_final]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final.to_csv(\"nhc_covid19_rf_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhc_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
